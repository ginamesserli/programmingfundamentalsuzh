---
title: 'Exercise 2: Assignment'
author: "Philipp Kling"
date: "16.06.2020"
output:
  html_document:
    code_folding: show
    fig_height: 6
    highlight: tango
    theme: spacelab
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
editor_options:
  chunk_output_type: console
---



```{r knitr_init, include=TRUE}
library(knitr)

### Global options
options(max.print="75")
opts_chunk$set(echo=FALSE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
rm(list = ls())
```

# Preparation

# Assignment 1: Recoginition, loading, extraction


### Recognition

In the Github repository under data/ex2, you will find two files: file_a and file_b. Use a text editor of your choice, inspect each file, and determine what type of data each file includes. 

*File A*: Könnte von der Struktur her entweder HTML oder XML sein. Da das file einen Verweis auf die xml-Version enthält, handelt es sich um ein *XML-file*.

*File B*: Das zweite File benutzt gewellte Klammern. Es handelt sich hier meines Erachtens deshalb um ein *JSON-file*.

### File A
Use an appropriate package to load the **file_a** into R. Try the functions associated with the package you used to load the data to get a feeling for the dataset and extract the following information with it.

 * Extract a list of the IDs of the books.

```{r,include=TRUE}

library(xml2)
#Laden der xml2 library, um File A in R laden zu können.

file_a <- read_xml("/Users/ginam/OneDrive/Dokumente/GitHub/fds-2020-exercise/data/ex2/file_a")
#Working Directory setzen

xml_contents(file_a)
#Inhalte der Nodes des Files A anzeigen.

xml_name(file_a)
#Namen der Root des Files anschauen

xml_name(xml_children(file_a))
#Namen der Unterknoten des Files anschauen. Unterknoten "book" -> Hier will ich hin

danceoff <- xml_find_all(file_a, "//book")
#Neues File erstellen, das nur die Buchinhalte enthält

xml_attrs(x=danceoff)
#Liste der Attribute aus dem neu-erstellten File ziehen, um an die id-Tags der Bücher zu gelangen.

```

* What is the name of the author of the 4th book?
```{r, inlcude=TRUe}
xml_name(xml_children(danceoff))
#Namen der Unterknoten des Files danceoff anschauen. Unterknoten "author" -> hier will ich hin.

authors <- xml_find_all(danceoff, "//author")
#File nur mit den Namne der Autor*innen erstellen.

authors
#Anzeigen lassen. Vierte Autorin ist Eva Corets.
```

*Antwort:Eva Corets.* 


### File B

Use an appropriate package to load the **file_b** into R. 

* What is the email of Mr. Bea?

```{r,include=TRUE}
library(jsonlite)
#packet jsonlite laden

file_b <-fromJSON("/Users/ginam/OneDrive/Dokumente/GitHub/fds-2020-exercise/data/ex2/file_b")
#file b in R laden

View(file_b)
#file_b anschauen, um herauszufinden, was die E-Mail von Mr. Bea ist.

file_b[3,4]
#Mr. Beas E-Mail rausgeben lassen.
```
*Die E-Mail von Mr. Bea lautet: nbea2@imageshack.us*

# Assignment 2: Extract date with Regular Expressions {.tabset .tabset-fade .tabset-pills}

You have the URL to an article of the Guardian. Use regular expressions to extract the publication date of the linked article. Your procedure should be generally applicable to the articles of The Guardian and not only apply to this single link. Use the package __stringr__ and its function __str_extract__ or optionally __str_replace__ to solve this task. (Hint: Slashes and Backslashes must be escaped with two preceding backslashes; e.g. '\ \ /' or '\ \ \'. The package lubridate and its function as_date() are helpful when trying to transform text to dates.)

```{r,include=TRUE}
url <- "https://www.theguardian.com/society/2018/oct/11/new-law-employers-reveal-race-pay-gap-figures"
#Structure: https://www.theguardian.com/category/year/month/day/headlinetext

result <- lubridate::as_date("2018-10-11")  # The result should look like this.

mopptop <- str_extract(url, "[0-9]{4}[\\/a-z]+[0-9]+")
#Regular expression erstellen, um Publikationsdatum aus String zu ziehen

coffeismyfriend <- lubridate::as_date(mopptop)
#In Datumsformat umwandeln

coffeismyfriend
#Datum ausgeben lassen

url2 <- "https://www.theguardian.com/society/1998/dec/25/new-law-employers-reveal-race-pay-gap-figures"
url3 <- "https://www.theguardian.com/society/2528/apr/05/new-law-employers-reveal-race-pay-gap-figures"

mopptop2 <- str_extract(url2, "[0-9]{4}[\\/a-z]+[0-9]+")
mopptop3 <- str_extract(url3, "[0-9]{4}[\\/a-z]+[0-9]+")

teaismyfriend <- lubridate::as_date(mopptop2)
waterismyfriend <- lubridate::as_date(mopptop3)

teaismyfriend
waterismyfriend
#Nachkontrolle anhand exemplarischer anderer Daten: funktioniert die regular expression, die ich gewählt habe, auch für andere Daten? Scheint der Fall zu sein (ist natürlich nicht vollständig, aber gibt ein Indiz darauf, dass es das sein könnte)
```

# Assignment 3: Translation

Take the content of file_b used in the first assignment. Transform it into an XML-File format by hand. You can use 
https://www.xmlvalidation.com to validate your attempts.

```{r, include=TRUE}
file_b_transformed <- read_xml("/Users/ginam/OneDrive/Dokumente/GitHub/fds-2020-exercise/data/ex2/file_b_transformed1")

xml_contents(file_b_transformed)
```
*Ich habe ein neues File erstellt, das ich file_b_transformed genannt habe. Um zu beweisen, dass ich file_b von Hand in ein XML-File übertragen habe, lese ich das transformierte file hier ein und wende dann wieder den xml_contents Befehl an.*



